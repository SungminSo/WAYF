{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소속 선수 수 상위 5개국\n",
    "# England Germany Spain Argentina France\n",
    "# 선수 사진으로 국적 분류\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import ImageOps\n",
    "from PIL import Image\n",
    "\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# referenced image_to_str in binary_cnn\n",
    "def image_to_str(path, one_hot_label):\n",
    "    with open(path, \"rb\") as f:\n",
    "        with Image.open(f) as img:\n",
    "            arr = np.array(img)[:,:,:3]\n",
    "            return \",\".join(map(str, arr.flat)) + \",\" + \",\".join(map(str, one_hot_label))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,71,65,59,37,28,20,0,0,0,0,0,0,20,6,1,50,44,41,73,67,59,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,78,69,48,43,41,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,33,22,19,72,68,63,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,82,83,74,41,37,32,0,0,0,0,0,0,169,180,175,85,81,75,71,66,58,60,55,49,55,50,44,59,55,48,66,64,59,76,73,64,181,210,203,0,0,0,0,0,0,0,0,0,69,65,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,63,58,0,0,0,0,0,0,88,92,81,72,69,64,63,58,54,59,51,46,56,48,40,54,45,41,60,49,44,58,48,42,58,49,45,63,53,47,57,50,46,58,54,47,83,83,79,0,0,0,0,0,0,38,34,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,64,57,0,0,0,109,121,104,75,72,67,61,58,53,57,53,49,53,46,42,60,48,44,56,43,40,62,49,47,68,55,51,63,51,46,63,49,46,62,49,46,66,52,47,62,52,47,59,52,48,65,61,54,82,80,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,62,60,54,0,0,0,88,87,82,59,58,51,63,58,54,57,51,48,58,50,48,66,53,51,58,44,41,61,46,44,69,53,51,65,52,49,72,56,53,67,53,50,63,50,46,73,57,51,73,58,55,56,44,40,52,44,41,57,52,44,66,65,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,75,74,66,0,0,0,100,102,92,63,58,54,48,42,39,50,41,37,61,50,45,66,54,50,71,55,51,70,56,51,67,55,51,70,54,50,84,64,59,86,65,60,79,61,57,76,60,54,86,69,63,76,60,56,58,44,42,55,44,39,56,44,42,54,49,43,65,61,57,0,0,0,47,43,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,68,67,59,60,55,50,73,56,51,88,64,58,90,65,59,114,84,76,125,93,84,131,100,93,136,107,98,136,104,94,132,97,91,125,93,87,117,85,78,103,76,70,108,80,76,102,76,71,99,71,64,100,73,63,94,73,67,72,61,57,57,49,48,74,68,67,0,0,0,63,56,55,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,67,62,58,0,0,0,86,82,78,70,65,59,103,84,79,131,97,91,142,100,94,156,110,100,194,141,128,210,155,144,217,164,155,216,166,156,224,173,165,221,169,162,217,163,156,213,158,148,208,155,145,204,150,141,200,144,137,182,130,123,168,120,108,145,105,99,122,96,90,77,68,63,69,64,58,0,0,0,50,43,41,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,53,46,42,0,0,0,74,70,66,95,81,74,146,110,104,154,110,104,173,125,114,188,134,120,201,145,133,211,153,144,211,151,138,219,162,152,230,171,164,231,172,164,230,173,165,228,172,161,219,161,148,214,155,143,208,149,142,195,137,127,188,135,123,180,134,126,166,131,125,116,98,92,74,71,66,100,100,91,0,0,0,87,86,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,166,149,143,79,72,65,120,97,88,149,108,100,163,116,110,178,127,119,190,135,126,203,144,137,208,147,138,219,160,149,230,174,167,233,175,168,235,180,174,237,182,177,232,178,168,227,170,163,218,157,150,206,146,137,198,139,132,189,133,125,183,134,128,174,135,130,144,117,111,93,86,80,86,88,80,0,0,0,85,83,76,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,99,93,85,0,0,0,105,101,92,86,77,70,135,102,97,156,112,106,166,118,112,188,135,131,197,140,134,209,146,139,221,157,151,230,172,163,238,187,180,244,194,190,245,200,194,242,195,186,241,193,186,236,186,179,226,168,155,220,160,154,207,150,141,189,133,121,184,133,124,178,137,133,160,127,122,111,99,94,93,89,83,0,0,0,88,81,75,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,98,88,81,0,0,0,109,101,94,97,84,77,137,100,94,160,113,110,170,122,117,192,140,135,202,146,138,211,155,142,225,170,158,238,187,180,245,204,198,247,207,201,249,208,207,246,203,198,243,199,190,240,195,186,234,184,175,228,173,169,212,154,148,198,141,134,189,139,133,179,135,130,167,131,125,130,114,107,102,98,92,0,0,0,98,89,83,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,86,78,0,0,0,110,103,95,102,87,80,130,98,92,158,114,110,169,123,115,195,140,134,204,149,142,212,157,144,221,162,154,239,186,180,246,203,195,247,209,202,247,205,197,247,203,197,244,200,192,241,195,187,232,180,172,227,167,161,219,160,154,206,151,148,186,140,133,176,134,127,169,132,128,143,122,117,114,110,105,0,0,0,73,43,46,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,94,85,78,0,0,0,103,96,90,100,87,82,135,103,96,162,119,112,171,126,117,194,141,133,208,153,144,209,151,141,221,159,152,235,177,169,242,195,186,245,200,191,247,205,196,246,201,192,243,198,189,240,189,182,233,177,171,224,164,156,214,155,147,206,152,142,192,143,134,178,137,131,169,134,127,144,122,117,120,113,109,255,255,255,138,71,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,114,94,92,0,0,0,105,101,95,102,90,85,137,107,99,163,123,116,173,128,120,190,137,131,209,156,149,213,160,151,221,166,159,233,176,169,240,191,183,241,194,183,245,200,191,245,202,191,242,197,188,241,192,183,235,183,174,225,170,163,216,162,154,214,158,151,194,141,135,174,134,129,164,133,126,138,119,114,113,104,99,255,255,255,0,0,0,177,141,130,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,101,96,92,99,86,82,138,110,105,165,128,122,174,131,125,198,147,141,210,158,152,219,167,158,228,172,165,233,180,173,242,197,190,244,204,193,246,205,195,247,206,198,245,201,192,243,197,188,237,188,179,227,173,166,221,169,162,213,161,154,193,143,137,176,135,131,169,136,132,127,111,107,89,81,76,101,126,108,188,169,142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,190,140,126,0,0,0,161,127,117,209,157,143,106,90,84,85,74,70,135,110,105,162,127,121,176,136,129,174,134,124,169,129,118,176,137,124,189,148,135,219,175,161,237,193,180,241,200,187,240,200,188,242,202,191,243,202,191,235,192,180,210,168,155,189,146,132,175,138,122,180,141,125,176,137,129,171,134,129,164,134,130,114,99,94,77,69,66,189,145,132,174,135,124,170,165,161,0,0,0,183,160,153,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,157,104,102,194,135,128,148,121,113,72,62,56,136,112,108,152,122,117,125,98,87,107,83,72,146,119,107,149,126,113,115,92,81,112,84,74,169,134,119,222,182,163,228,187,170,227,187,170,209,172,153,146,115,100,104,81,66,132,107,97,157,131,119,152,125,113,126,101,92,132,105,96,160,134,129,113,95,93,119,99,93,200,149,140,193,145,142,235,215,208,0,0,0,219,188,183,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,220,160,162,165,109,104,142,110,104,87,72,67,149,122,119,146,118,111,133,108,99,148,121,113,156,128,120,132,114,107,111,99,97,116,92,91,125,94,85,175,139,122,224,180,162,215,175,155,154,119,106,128,97,94,125,100,98,112,96,94,133,109,106,157,129,122,143,119,111,123,98,88,160,134,127,122,104,102,128,105,99,179,131,124,211,148,146,234,193,192,0,0,0,227,178,176,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,42,21,0,0,0,213,159,155,210,150,138,164,124,118,100,81,77,146,120,113,170,138,127,198,164,153,168,137,125,130,101,95,104,93,100,118,116,121,190,164,164,191,158,155,180,143,133,237,188,175,216,172,160,187,156,149,202,171,172,179,152,156,116,108,119,117,99,107,139,113,107,187,159,147,194,160,148,171,141,132,134,114,110,139,109,106,217,159,156,214,149,142,225,190,189,0,0,0,224,182,178,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,192,134,125,0,0,0,191,146,138,232,174,170,206,154,150,118,94,89,139,115,106,194,159,146,215,175,160,220,182,170,219,183,175,219,187,183,223,187,185,233,196,193,217,184,178,194,143,135,229,176,171,211,159,152,200,156,148,228,197,192,228,189,186,222,187,183,225,189,185,219,183,173,220,183,167,222,183,169,189,154,145,135,112,108,176,133,131,236,178,179,216,160,156,209,175,172,0,0,0,214,175,172,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,206,155,151,0,0,0,204,156,153,237,180,178,227,176,177,119,99,90,119,99,90,180,144,132,210,164,154,226,173,166,237,193,187,233,192,187,232,189,185,228,181,173,194,143,133,187,131,125,228,172,169,210,156,153,191,135,130,216,164,156,232,186,177,227,182,172,228,179,171,231,181,172,226,178,167,217,175,163,173,143,135,127,108,101,200,153,150,239,175,176,217,165,165,196,168,166,0,0,0,215,176,175,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,216,162,157,0,0,0,218,163,158,218,162,157,211,160,152,127,99,91,106,91,87,167,133,124,199,150,143,215,159,150,235,177,173,239,184,179,240,182,176,225,167,159,184,134,127,184,129,124,217,149,151,205,144,143,192,142,139,219,167,157,236,183,173,237,182,177,235,178,173,231,170,167,215,164,154,197,155,141,153,128,116,122,101,94,208,155,155,239,178,179,213,159,159,0,0,0,205,139,137,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,203,159,149,0,0,0,204,160,154,243,187,176,172,131,119,102,88,86,154,127,118,183,140,131,213,152,148,237,180,181,237,185,183,235,183,177,206,155,150,170,121,118,198,138,138,233,172,178,213,149,152,186,133,133,199,149,147,234,189,176,237,184,180,236,183,181,228,170,166,207,153,146,180,145,134,132,114,108,139,114,105,241,194,188,214,166,162,217,161,156,0,0,0,218,168,164,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,211,161,154,0,0,0,180,150,145,212,156,150,190,144,133,109,94,87,134,115,107,163,128,123,213,156,153,230,173,170,216,163,154,219,174,161,172,125,120,165,113,114,195,143,141,237,183,183,212,153,154,177,124,126,175,124,128,219,176,164,223,175,163,226,170,166,229,173,167,203,152,143,165,132,122,122,105,99,157,125,115,227,175,170,214,172,173,0,0,0,218,169,167,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,208,157,150,0,0,0,0,0,0,255,255,255,117,104,93,132,113,104,148,120,116,201,150,145,206,157,147,216,172,159,227,182,171,167,123,117,108,75,70,97,68,63,132,96,92,115,82,77,116,82,77,159,116,111,224,173,167,228,189,173,210,163,151,210,162,154,187,148,140,151,124,115,132,113,106,148,127,119,255,236,231,0,0,0,212,161,157,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,203,157,150,123,92,86,0,0,0,120,103,95,134,113,104,142,119,109,196,154,143,216,173,157,204,166,151,202,159,151,199,154,149,192,147,141,175,136,133,143,111,111,177,137,137,202,159,153,205,161,155,206,164,155,205,164,149,213,174,159,210,170,157,180,147,133,152,128,116,122,106,97,133,127,112,0,0,0,178,147,139,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,123,103,90,0,0,0,123,105,92,135,112,100,138,113,100,196,158,144,225,187,167,194,159,137,170,136,123,176,138,132,191,141,140,212,155,160,225,167,172,218,161,163,196,143,145,177,134,132,158,122,115,192,155,140,212,177,156,221,181,163,175,145,129,159,136,121,126,111,102,250,241,234,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,129,115,100,0,0,0,129,116,101,129,109,98,138,112,103,171,139,127,226,186,172,220,183,165,186,146,137,137,81,88,143,93,99,168,126,129,168,119,122,169,121,124,158,110,118,147,86,99,174,120,125,209,172,159,218,183,169,209,172,159,159,131,117,155,130,119,128,110,100,0,0,0,103,80,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,143,131,116,0,0,0,150,139,124,128,110,95,126,103,94,138,115,105,196,162,149,211,170,159,226,181,171,202,146,144,189,130,134,203,150,157,212,162,170,204,151,160,196,138,147,207,145,151,226,181,174,217,180,167,199,166,155,170,141,132,134,111,102,137,117,104,144,129,113,0,0,0,137,120,105,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,122,111,101,0,0,0,133,122,112,109,96,85,118,98,89,120,101,94,156,131,122,177,143,134,205,158,148,209,163,152,200,153,146,208,157,158,209,158,161,210,161,162,209,159,156,214,164,157,215,172,164,191,156,146,180,150,140,139,115,108,119,98,94,126,112,102,144,131,116,0,0,0,132,119,105,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,113,101,95,0,0,0,132,118,111,78,67,63,109,92,86,125,105,100,144,118,112,152,123,114,180,141,132,215,167,158,211,164,155,200,155,148,188,146,141,201,156,149,212,165,158,219,171,163,187,149,141,173,143,135,173,144,139,124,104,100,112,99,94,102,92,85,118,107,101,0,0,0,113,103,97,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,126,114,107,0,0,0,153,141,133,96,80,73,57,48,43,110,96,90,134,111,105,144,117,109,165,130,124,201,153,145,210,154,150,215,158,157,210,153,154,211,153,154,211,156,153,204,158,153,168,135,130,160,128,122,148,126,122,118,105,102,84,75,71,96,85,81,152,141,135,0,0,0,132,121,116,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,144,127,121,0,0,0,160,147,141,120,100,95,77,61,56,54,46,44,105,92,88,141,117,112,157,121,117,176,131,131,191,138,141,210,153,155,214,159,160,207,149,153,191,138,139,180,135,134,180,138,134,148,120,116,109,98,97,82,72,72,82,66,64,127,110,105,145,142,138,0,0,0,139,129,124,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,200,192,126,104,100,140,111,105,72,53,52,42,36,35,113,96,93,149,122,118,161,125,123,193,145,146,210,162,161,210,165,163,206,159,159,189,144,145,178,135,134,178,142,137,118,102,100,65,55,55,84,67,67,140,112,107,139,118,112,153,148,143,0,0,0,150,137,131,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,24,67,0,0,0,127,106,98,158,122,116,156,117,113,66,48,45,39,34,31,99,84,83,136,113,109,155,125,119,168,133,127,178,142,139,167,134,129,166,134,131,160,136,134,117,102,104,52,43,43,86,67,65,171,134,133,163,128,123,139,115,110,164,154,150,0,0,0,162,146,138,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,108,141,0,0,0,168,155,141,129,107,101,152,117,114,182,139,136,154,114,110,63,45,41,21,15,17,53,42,45,69,54,56,75,61,61,77,63,64,76,61,63,83,69,73,71,63,67,47,36,40,90,69,69,172,137,136,187,145,145,162,127,123,143,118,112,179,160,146,0,0,0,107,114,148,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,74,106,168,50,80,147,0,0,0,110,119,145,115,104,104,125,103,99,158,122,118,179,136,132,190,145,141,144,108,106,73,54,54,43,30,33,39,26,32,42,28,34,46,32,37,44,31,36,46,33,37,63,47,49,112,88,85,185,147,146,198,156,153,175,136,134,166,131,127,152,126,122,139,123,121,165,149,137,0,0,0,36,67,149,74,103,170,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,114,183,52,90,172,0,0,0,0,0,0,84,118,180,61,91,153,107,96,102,126,99,94,158,120,115,181,141,138,198,152,152,195,143,142,164,124,122,133,102,102,122,97,97,111,91,90,114,92,91,116,96,97,120,97,98,150,120,115,199,160,155,216,172,169,200,157,155,184,146,142,175,139,132,152,124,120,145,123,117,90,106,151,61,110,198,0,0,0,0,0,0,0,33,154,65,101,178,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,103,183,0,0,0,0,0,0,93,124,178,63,94,161,52,81,149,39,76,153,97,90,103,139,109,101,157,119,114,183,136,133,204,157,155,212,165,163,206,161,159,186,147,144,183,147,144,179,147,145,180,148,147,188,156,154,188,155,152,203,167,163,218,180,176,217,175,172,201,160,156,189,153,147,183,145,137,166,130,125,127,112,114,57,88,163,50,85,162,64,95,168,78,105,171,0,0,0,0,0,0,0,0,0,67,102,173,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,106,167,56,89,166,0,0,0,0,0,0,113,142,213,69,102,175,52,85,157,47,82,163,41,72,144,28,66,143,77,86,123,143,109,97,159,123,120,182,139,135,200,154,149,216,169,166,223,176,174,215,172,169,205,165,164,209,170,170,211,176,173,211,175,170,215,174,172,223,180,177,223,183,179,214,174,170,205,169,163,193,155,149,196,158,151,178,143,132,119,109,125,41,78,167,44,76,154,48,83,164,53,86,162,62,94,163,75,111,182,227,226,188,0,0,0,0,0,0,56,89,164,61,92,164,0,0,0,0,0,0,0,0,0,0,0,0,62,102,180,0,12,110,0,0,0,0,0,0,179,207,248,73,114,185,58,94,169,55,89,172,42,73,147,42,77,152,38,71,144,27,66,146,54,82,149,148,119,114,166,131,127,182,140,134,203,158,155,215,169,165,221,175,169,225,181,180,215,172,171,214,174,173,213,174,172,214,176,173,224,185,182,229,190,185,224,185,180,217,177,172,203,165,160,206,166,161,199,162,156,188,153,139,102,112,155,34,75,167,43,74,149,42,74,151,43,76,153,48,81,160,56,91,174,65,100,174,74,110,175,0,0,0,0,0,0,0,0,0,55,87,162,74,106,177,0,0,0,0,0,0,0,0,0,0,0,0,86,113,171,73,98,164,61,93,169,55,92,176,47,86,169,43,85,172,39,77,157,33,69,142,38,84,175,34,80,171,35,76,159,141,122,129,163,130,119,180,141,135,204,162,159,213,173,168,225,180,175,226,180,176,220,179,176,216,177,175,223,182,180,229,190,186,231,193,191,228,188,182,222,183,178,217,176,172,208,171,165,216,182,175,207,175,173,206,172,164,72,103,174,32,84,183,38,83,172,37,78,162,40,76,156,41,80,163,41,82,167,50,88,176,57,91,168,58,91,164,58,90,164,75,103,164,0,0,0,0,0,0,0,0,0,117,136,183,72,106,178,61,94,164,57,89,162,54,89,169,46,80,156,47,84,171,43,79,162,38,77,156,39,86,176,33,81,171,29,77,165,37,85,176,20,70,163,103,106,140,171,137,125,175,140,137,193,156,152,210,170,164,222,182,175,223,184,179,224,186,181,225,190,185,228,193,190,226,188,182,223,184,179,226,184,180,228,189,184,220,185,181,216,182,175,211,181,174,206,175,168,175,163,172,36,80,164,37,87,181,37,86,181,39,88,183,38,85,174,39,80,165,41,80,162,43,81,163,46,80,161,50,82,160,54,88,169,56,87,159,64,92,162,77,108,174,0,0,0,1,0,0,0,0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/Users/ssm74/Projects/WAYF/Data/valid_pictures/England/54050.png\"\n",
    "image_to_str(path, [1, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# England Germany Spain Argentina France\n",
    "path = \"C:/Users/ssm74/Projects/WAYF/Data/valid_pictures\"\n",
    "name_one_hot = [ (\"England\", (1, 0, 0, 0, 0)), \n",
    "                 (\"Germany\", (0, 1, 0, 0, 0)),\n",
    "                 (\"Spain\", (0, 0, 1, 0, 0)),\n",
    "                 (\"Argentina\", (0, 0, 0, 1, 0)),\n",
    "                 (\"France\", (0, 0, 0, 0, 1))\n",
    "               ]\n",
    "\n",
    "with open(\"5_cnn_data.csv\", \"w\") as f:\n",
    "    for name, one_hot in name_one_hot:\n",
    "        directory_path = path + \"/\" + name\n",
    "        for id in os.listdir(directory_path):\n",
    "            img_path = directory_path + \"/\" + id\n",
    "            f.write(image_to_str(img_path, one_hot) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4806, 6917)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = []\n",
    "\n",
    "with open(\"./5_cnn_data.csv\", \"r\") as f:\n",
    "    for line in f:\n",
    "        arr.append(list(map(int, line.split(\",\"))))\n",
    "        \n",
    "arr = np.array(arr)\n",
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    '''\n",
    "    파라미터(가중치 텐서)의 초깃값을 정하는 함수\n",
    "    표준편차가 0.1인 절단정규분포 이용\n",
    "    '''\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial, name=\"weights\")\n",
    "\n",
    "def bias_variable(shape):\n",
    "    '''\n",
    "    편향값의 초깃값을 정하는 함수\n",
    "    '''\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, w):\n",
    "    '''\n",
    "    합성곱을 구하는 함수\n",
    "    입력값 x를 필터 텐서 w를 이용하여 변형\n",
    "    stride = 1, padding = SAME\n",
    "    변형된 이미지는 입력 이미지와 높이, 너비가 같음\n",
    "    '''    \n",
    "    return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding=\"SAME\", name=\"conv\")\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    '''\n",
    "    2x2 윈도우 안의 최댓값을 뽑아 새로운 텐서 생성\n",
    "    stride가 2이기 때문에 출력 텐서의 높이와 너비는 입력 텐서의 1/2가 됨\n",
    "    '''    \n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\", name=\"pool\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, train_accuracy: 0.317614\n",
      "step: 1, train_accuracy: 0.308599\n",
      "step: 2, train_accuracy: 0.300277\n",
      "step: 3, train_accuracy: 0.29681\n",
      "step: 4, train_accuracy: 0.296117\n",
      "step: 5, train_accuracy: 0.29681\n",
      "step: 6, train_accuracy: 0.307212\n",
      "step: 7, train_accuracy: 0.298197\n",
      "step: 8, train_accuracy: 0.301664\n",
      "step: 9, train_accuracy: 0.319001\n",
      "step: 10, train_accuracy: 0.304438\n",
      "step: 11, train_accuracy: 0.332178\n",
      "step: 12, train_accuracy: 0.334951\n",
      "step: 13, train_accuracy: 0.32663\n",
      "step: 14, train_accuracy: 0.334258\n",
      "step: 15, train_accuracy: 0.327323\n",
      "step: 16, train_accuracy: 0.352288\n",
      "step: 17, train_accuracy: 0.365465\n",
      "step: 18, train_accuracy: 0.402913\n",
      "step: 19, train_accuracy: 0.395284\n",
      "step: 20, train_accuracy: 0.375173\n",
      "step: 21, train_accuracy: 0.409847\n",
      "step: 22, train_accuracy: 0.399445\n",
      "step: 23, train_accuracy: 0.385576\n",
      "step: 24, train_accuracy: 0.417476\n",
      "step: 25, train_accuracy: 0.409154\n",
      "step: 26, train_accuracy: 0.399445\n",
      "step: 27, train_accuracy: 0.414008\n",
      "step: 28, train_accuracy: 0.395978\n",
      "step: 29, train_accuracy: 0.405687\n",
      "step: 30, train_accuracy: 0.40846\n",
      "step: 31, train_accuracy: 0.43828\n",
      "step: 32, train_accuracy: 0.420943\n",
      "step: 33, train_accuracy: 0.429265\n",
      "step: 34, train_accuracy: 0.440361\n",
      "step: 35, train_accuracy: 0.428571\n",
      "step: 36, train_accuracy: 0.458391\n",
      "step: 37, train_accuracy: 0.462552\n",
      "step: 38, train_accuracy: 0.446602\n",
      "step: 39, train_accuracy: 0.4681\n",
      "step: 40, train_accuracy: 0.480583\n",
      "step: 41, train_accuracy: 0.466019\n",
      "step: 42, train_accuracy: 0.48613\n",
      "step: 43, train_accuracy: 0.481969\n",
      "step: 44, train_accuracy: 0.490291\n",
      "step: 45, train_accuracy: 0.493065\n",
      "step: 46, train_accuracy: 0.479196\n",
      "step: 47, train_accuracy: 0.488904\n",
      "step: 48, train_accuracy: 0.511789\n",
      "step: 49, train_accuracy: 0.497226\n",
      "step: 50, train_accuracy: 0.503467\n",
      "step: 51, train_accuracy: 0.494452\n",
      "step: 52, train_accuracy: 0.48405\n",
      "step: 53, train_accuracy: 0.512483\n",
      "step: 54, train_accuracy: 0.48613\n",
      "step: 55, train_accuracy: 0.522191\n",
      "step: 56, train_accuracy: 0.518724\n",
      "step: 57, train_accuracy: 0.518724\n",
      "step: 58, train_accuracy: 0.527739\n",
      "step: 59, train_accuracy: 0.504854\n",
      "step: 60, train_accuracy: 0.489598\n",
      "step: 61, train_accuracy: 0.522885\n",
      "step: 62, train_accuracy: 0.532594\n",
      "step: 63, train_accuracy: 0.509709\n",
      "step: 64, train_accuracy: 0.530513\n",
      "step: 65, train_accuracy: 0.539528\n",
      "step: 66, train_accuracy: 0.518031\n",
      "step: 67, train_accuracy: 0.52982\n",
      "step: 68, train_accuracy: 0.5319\n",
      "step: 69, train_accuracy: 0.526352\n",
      "step: 70, train_accuracy: 0.54577\n",
      "step: 71, train_accuracy: 0.541609\n",
      "step: 72, train_accuracy: 0.550624\n",
      "step: 73, train_accuracy: 0.54785\n",
      "step: 74, train_accuracy: 0.546463\n",
      "step: 75, train_accuracy: 0.554092\n",
      "step: 76, train_accuracy: 0.542996\n",
      "step: 77, train_accuracy: 0.563107\n",
      "step: 78, train_accuracy: 0.566574\n",
      "step: 79, train_accuracy: 0.548544\n",
      "step: 80, train_accuracy: 0.536061\n",
      "step: 81, train_accuracy: 0.574202\n",
      "step: 82, train_accuracy: 0.565881\n",
      "step: 83, train_accuracy: 0.566574\n",
      "step: 84, train_accuracy: 0.564494\n",
      "step: 85, train_accuracy: 0.579057\n",
      "step: 86, train_accuracy: 0.575589\n",
      "step: 87, train_accuracy: 0.5638\n",
      "step: 88, train_accuracy: 0.564494\n",
      "step: 89, train_accuracy: 0.565881\n",
      "step: 90, train_accuracy: 0.567961\n",
      "step: 91, train_accuracy: 0.588072\n",
      "step: 92, train_accuracy: 0.567961\n",
      "step: 93, train_accuracy: 0.57975\n",
      "step: 94, train_accuracy: 0.571429\n",
      "step: 95, train_accuracy: 0.583218\n",
      "step: 96, train_accuracy: 0.576976\n",
      "step: 97, train_accuracy: 0.572122\n",
      "step: 98, train_accuracy: 0.579057\n",
      "step: 99, train_accuracy: 0.590846\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def main(_):\n",
    "    '''\n",
    "    모델 학습과 결과 출력\n",
    "    '''\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, [None, 48, 48, 3], name=\"x\")\n",
    "    y = tf.placeholder(tf.float32, [None, 5], name=\"y\")\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    train_size = 3364\n",
    "    image_size = 6912\n",
    "    \n",
    "    with tf.name_scope(\"first_layer\"):\n",
    "        w_conv1 = weight_variable([3, 3, 3, 32])\n",
    "        b_conv1 = bias_variable([32])\n",
    "        \n",
    "        h_conv1 = tf.nn.relu(conv2d(x, w_conv1) + b_conv1, name=\"h_conv1\")\n",
    "        # h_conv1 shape = [?, 48, 48, 32]\n",
    "        \n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "        # h_pool1 shape = [?, 24, 24, 32]\n",
    "        \n",
    "    with tf.name_scope(\"second_layer\"):\n",
    "        w_conv2 = weight_variable([3, 3, 32, 64])\n",
    "        b_conv2 = bias_variable([64])\n",
    "        \n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2, name=\"h_conv2\")\n",
    "        # h_conv2 shape = [?. 24, 24, 64]\n",
    "        \n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        # h_pool2 shape = [?, 12, 12, 64]\n",
    "    \n",
    "    with tf.name_scope(\"third_layer\"):\n",
    "        w_conv3 = weight_variable([3, 3, 64, 128])\n",
    "        b_conv3 = bias_variable([128])\n",
    "        \n",
    "        h_conv3 = tf.nn.relu(conv2d(h_pool2, w_conv3) + b_conv3, name=\"h_conv3\")\n",
    "        # h_conv3 shape = [?. 12, 12, 128]\n",
    "        \n",
    "        h_pool3 = max_pool_2x2(h_conv3)\n",
    "        # h_pool2 shape = [?, 6, 6, 128]\n",
    "    \n",
    "    with tf.name_scope(\"first_fc\"):\n",
    "        w_fc1 = weight_variable([6*6*128, 1024])\n",
    "        b_fc1 = bias_variable([1024])\n",
    "        \n",
    "        h_pool3_flat = tf.reshape(h_pool3, [-1, 6*6*128])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, w_fc1) + b_fc1, name=\"h_fc1\")\n",
    "        \n",
    "    with tf.name_scope(\"drop_out\"):\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "        \n",
    "    with tf.name_scope(\"second_fc\"):\n",
    "        w_fc2 = weight_variable([1024, 5])\n",
    "        b_fc2 = bias_variable([5])\n",
    "        \n",
    "    y_conv = tf.matmul(h_fc1_drop, w_fc2) + b_fc2\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=y),\n",
    "                                name=\"croess_entropy\")\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for i in range(100):\n",
    "            np.random.shuffle(arr)\n",
    "            trX = arr[:train_size, :image_size].reshape((-1, 48, 48, 3))\n",
    "            trY = arr[:train_size, image_size:]\n",
    "            \n",
    "            sess.run(train_step, feed_dict={x: trX, y: trY, keep_prob:0.5})\n",
    "            \n",
    "            teX = arr[train_size: , :image_size].reshape((-1, 48, 48, 3))\n",
    "            teY = arr[train_size: , image_size:]\n",
    "            \n",
    "            # 평가 시에는 완성된 모델을 사용하기 위해\n",
    "            # dropout을 하지 않으므로 keep_prob = 1\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: teX, y:teY, keep_prob:1.0})\n",
    "            print(\"step: %d, train_accuracy: %g\" % (i, train_accuracy))\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
