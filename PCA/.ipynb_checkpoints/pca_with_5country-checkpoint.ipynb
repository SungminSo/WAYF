{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### England  Germany Spain  Argentina France  5국가 분류\n",
    "\n",
    "### 1. PCA + SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(fin):\n",
    "    \"\"\" 이미지 파일을 읽어 들여 이미지 데이터, 국가를 리턴\"\"\"\n",
    "    data = pd.read_csv(fin)\n",
    "    target_li=[]\n",
    "    data_li=[]\n",
    "    for i in range(len(data)):\n",
    "        image_id = int(data.iloc[i][0])\n",
    "        target_nation = data.iloc[i][3]\n",
    "        working_dir = fin.split('/')[:-1]\n",
    "        image_path = '/'.join(working_dir)+'/valid_pictures/'+ target_nation +'/{}.png'.format(image_id)\n",
    "       \n",
    "        if (os.path.isfile(image_path)):\n",
    "            image_data = cv2.imread(image_path, 0)\n",
    "            data_li.append(image_data)\n",
    "            target_li.append(target_nation)\n",
    "\n",
    "    return (np.array(data_li), np.array(target_li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_data(image_data, label_li):\n",
    "    #데이터 수, 세로 픽셀, 가로 픽셀 \n",
    "    n_samples, image_h, image_w = image_data.shape\n",
    "\n",
    "    X = image_data.reshape(n_samples, -1)\n",
    " \n",
    "    n_features = X.shape[1]\n",
    "    y = label_li\n",
    "    #클래스 갯수 = 분류할 국가 수\n",
    "    n_classes = 5\n",
    "    \n",
    "    print(\"total dataset size:\")\n",
    "    print(\"n_samples: %d\" % n_samples)\n",
    "    print(\"n_features: %d\" % n_features)\n",
    "    print(\"n_classes: %d\" % n_classes)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    return(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(X_train, X_test, n_components):\n",
    "    print(\"Extracting the top %d eigenfaces from %d faces\"\n",
    "         % (n_components, X_train.shape[0]))\n",
    "    pca = PCA(n_components = n_components,\n",
    "             svd_solver='randomized', whiten=True).fit(X_train)\n",
    "    \n",
    "    eigenfaces = pca.components_.reshape((n_components, 48, 48))\n",
    "    #주성분 차원바꾸기\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test) \n",
    "    \n",
    "    return(X_train_pca, X_test_pca, eigenfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier(X_train_pca, X_test_pca, y_train, y_test):\n",
    "    print(\"Fitting the classifier to the training set\")\n",
    "    param_grid={'C':[1e3,1e4],\n",
    "               'gamma':[0.001, 0.005, 0.01],}\n",
    "    clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "    clf = clf.fit(X_train_pca, y_train)\n",
    "    print(\"best estimator found by grid search\")\n",
    "    print(clf.best_estimator_)\n",
    "    print(\"predicting people's names on the test set\")\n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_gallery(images, n_col=5):\n",
    "    n_row = round(images.shape[0]/n_col)\n",
    "    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    plt.subplots_adjust(bottom=0.1, left=0.01, right=0.99, top=0.90, hspace=0.35)\n",
    "    \n",
    "    for i in range(n_row * n_col):\n",
    "        plt.subplot(n_row, n_col, i+1)\n",
    "        #플롯값의 최대치를 흰색으로, 최소치를 검은색으로 변환 ( 특징이 되는 곳이 흰색으로 두드러지게 하는것)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total dataset size:\n",
      "n_samples: 4805\n",
      "n_features: 2304\n",
      "n_classes: 5\n",
      "Extracting the top 20 eigenfaces from 3603 faces\n",
      "Fitting the classifier to the training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HanSung\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best estimator found by grid search\n",
      "SVC(C=1000.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "predicting people's names on the test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Argentina       0.31      0.44      0.37       152\n",
      "     England       0.67      0.48      0.55       385\n",
      "      France       0.41      0.46      0.44       191\n",
      "     Germany       0.60      0.63      0.62       276\n",
      "       Spain       0.49      0.53      0.51       198\n",
      "\n",
      "    accuracy                           0.51      1202\n",
      "   macro avg       0.50      0.51      0.50      1202\n",
      "weighted avg       0.54      0.51      0.52      1202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "argv = sys.argv\n",
    "image_data, label = read_data('D:/DL/WAYF/Data/5country.csv')\n",
    "#몇차원으로 압축?\n",
    "n_eigenface = 20\n",
    "X_train, X_test, y_train, y_test = create_train_test_data(image_data, label)\n",
    "X_train_pca, X_test_pca, eigenface = extract_features(X_train, X_test, n_eigenface)\n",
    "train_test_classifier(X_train_pca, X_test_pca, y_train, y_test)\n",
    "#보여줄 필요는 없음\n",
    "#plot_gallery(eigenface)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_classifier_kmeans(X_train_pca, X_test_pca, y_train, y_test):\n",
    "    clf = KMeans(n_clusters=5, init=\"k-means++\", n_init=10, max_iter=100, random_state=42)\n",
    "    clf.fit(X_train_pca) \n",
    "    print(\"predicting people's names on the test set\")\n",
    "  \n",
    " #그룹별 나라를 아무거나 붙여주면 정확도 10% 대 \n",
    " #    label_encoder = preprocessing.LabelEncoder() \n",
    "#    y_test = label_encoder.fit_transform(y_test) \n",
    "    \n",
    "    y_pred = clf.predict(X_test_pca)\n",
    "  \n",
    " #클러스터링으로 니온 그룹별(번호)에 나라 이름을 붙여줌. np.where(if문, 조건 o, 조건 x)\n",
    "    y_pred = np.where(y_pred == 0, 'England',\n",
    "         np.where(y_pred == 1, 'Germany',\n",
    "                  np.where(y_pred == 4, 'France', \n",
    "                           np.where(y_pred == 3, 'Spain', 'Argentina'))))\n",
    "            \n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting people's names on the test set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Argentina       0.15      0.24      0.18       152\n",
      "     England       0.59      0.22      0.32       385\n",
      "      France       0.24      0.39      0.30       191\n",
      "     Germany       0.44      0.26      0.32       276\n",
      "       Spain       0.24      0.40      0.30       198\n",
      "\n",
      "    accuracy                           0.29      1202\n",
      "   macro avg       0.33      0.30      0.28      1202\n",
      "weighted avg       0.38      0.29      0.30      1202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_classifier_kmeans(X_train_pca, X_test_pca, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
